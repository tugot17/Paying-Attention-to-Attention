{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human to machine date translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now there is some problem with cuda so only cpu versio is working on\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>machine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>friday october 20 1995</td>\n",
       "      <td>1995-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19 may 2011</td>\n",
       "      <td>2011-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monday december 19 1994</td>\n",
       "      <td>1994-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saturday june 22 1991</td>\n",
       "      <td>1991-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>november 4 1999</td>\n",
       "      <td>1999-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>july 16 1980</td>\n",
       "      <td>1980-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>friday august 11 1995</td>\n",
       "      <td>1995-08-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>august 16 2015</td>\n",
       "      <td>2015-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>jul 2 1980</td>\n",
       "      <td>1980-07-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>13 aug 1997</td>\n",
       "      <td>1997-08-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        human     machine\n",
       "0      friday october 20 1995  1995-10-20\n",
       "1                 19 may 2011  2011-05-19\n",
       "2     monday december 19 1994  1994-12-19\n",
       "3       saturday june 22 1991  1991-06-22\n",
       "4             november 4 1999  1999-11-04\n",
       "...                       ...         ...\n",
       "9995             july 16 1980  1980-07-16\n",
       "9996    friday august 11 1995  1995-08-11\n",
       "9997           august 16 2015  2015-08-16\n",
       "9998               jul 2 1980  1980-07-02\n",
       "9999              13 aug 1997  1997-08-13\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.path.join('human-machine.csv')\n",
    "\n",
    "df = pd.read_csv(PATH, index_col=0)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computers don't understand letters, so we need numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDict:\n",
    "    def __init__(self):\n",
    "        self.char2index = {}\n",
    "        self.char2count = {}\n",
    "        self.index2char = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.n_chars = 2\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for c in sentence:\n",
    "            self.addChar(c)\n",
    "\n",
    "    def addChar(self, char):\n",
    "        if char not in self.char2index:\n",
    "            self.char2index[char] = self.n_chars\n",
    "            self.char2count[char] = 1\n",
    "            self.index2char[self.n_chars] = char\n",
    "            self.n_chars += 1\n",
    "        else:\n",
    "            self.char2count[char] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    df = pd.read_csv(PATH)\n",
    "    human = df[\"human\"].values\n",
    "    machine = df[\"machine\"].values\n",
    "    pairs = []\n",
    "    for i in range(len(human)):\n",
    "        pairs.append([human[i], machine[i]])\n",
    "\n",
    "    input_lang = CharDict()\n",
    "    output_lang = CharDict()\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input char indices: {'f': 2, 'r': 3, 'i': 4, 'd': 5, 'a': 6, 'y': 7, ' ': 8, 'o': 9, 'c': 10, 't': 11, 'b': 12, 'e': 13, '2': 14, '0': 15, '1': 16, '9': 17, '5': 18, 'm': 19, 'n': 20, '4': 21, 's': 22, 'u': 23, 'j': 24, 'v': 25, 'w': 26, '7': 27, 'l': 28, '8': 29, 'h': 30, '6': 31, 'p': 32, '3': 33, '.': 34, '/': 35, 'g': 36}\n",
      "\n",
      "Example pair: ['november 27 1999', '1999-11-27']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data()\n",
    "\n",
    "print(f\"Input char indices: {input_lang.char2index}\")\n",
    "print()\n",
    "print(f\"Example pair: {pairs[2137]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.char2index[char] for char in sentence]\n",
    "\n",
    "\n",
    "def variable_from_sentence(lang, sentence):\n",
    "    indexes = indexes_from_sentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    var = Variable(torch.LongTensor(indexes).view(-1, 1)).to(device)\n",
    "    # if USE_CUDA: var = var.cuda()\n",
    "    return var\n",
    "\n",
    "\n",
    "def variables_from_pair(pair):\n",
    "    input_variable = variable_from_sentence(input_lang, pair[0])\n",
    "    target_variable = variable_from_sentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human input november 27 1999\n",
      "Machine output 1999-11-27\n",
      "Real input length: 16, parsed input shhape: torch.Size([17, 1])\n",
      "Real output length: 10, parsed input shhape: torch.Size([11, 1])\n",
      "\n",
      "Parsed human input tensor([[20],\n",
      "        [ 9],\n",
      "        [25],\n",
      "        [13],\n",
      "        [19],\n",
      "        [12],\n",
      "        [13],\n",
      "        [ 3],\n",
      "        [ 8],\n",
      "        [14],\n",
      "        [27],\n",
      "        [ 8],\n",
      "        [16],\n",
      "        [17],\n",
      "        [17],\n",
      "        [17],\n",
      "        [ 1]])\n",
      "Parsed machine output tensor([[ 2],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 3],\n",
      "        [ 5],\n",
      "        [ 2],\n",
      "        [ 2],\n",
      "        [ 5],\n",
      "        [ 7],\n",
      "        [10],\n",
      "        [ 1]])\n"
     ]
    }
   ],
   "source": [
    "pair = ['november 27 1999', '1999-11-27']\n",
    "\n",
    "print(f\"Human input {pair[0]}\")\n",
    "print(f\"Machine output {pair[1]}\")\n",
    "\n",
    "input_variable, target_variable = variables_from_pair(pair)\n",
    "\n",
    "print(f\"Real input length: {len(pair[0])}, parsed input shhape: {input_variable.shape}\")\n",
    "print(f\"Real output length: {len(pair[1])}, parsed input shhape: {target_variable.shape}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Parsed human input {input_variable}\")\n",
    "print(f\"Parsed machine output {target_variable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "\n",
    "<img src=\"images/seq2seq.png\"/>\n",
    "\n",
    "1. Embed\n",
    "2. Encode\n",
    "3. Attend\n",
    "4. Predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "<img src=\"images/encoder-network.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chars in input data: 37\n",
      "Hidden state: tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
      "Output shape: torch.Size([1, 1, 64])\n",
      "Hidden state shape: torch.Size([1, 1, 64])\n",
      "Output: tensor([[[-0.0478, -0.5431,  0.0997, -0.2324,  0.0138,  0.1760, -0.0274,\n",
      "          -0.0999, -0.0684, -0.1663,  0.2475,  0.0884, -0.3003, -0.2772,\n",
      "          -0.2035, -0.1211,  0.2084,  0.3077,  0.4153,  0.2399,  0.3368,\n",
      "           0.1871, -0.1179, -0.1679,  0.0261,  0.1721,  0.0880, -0.1811,\n",
      "           0.1808,  0.0879, -0.0167,  0.0511,  0.0214, -0.1042,  0.0921,\n",
      "          -0.0821, -0.5229, -0.0615, -0.3729, -0.2019,  0.2015,  0.0625,\n",
      "          -0.0060,  0.4505, -0.1952,  0.0985, -0.2364, -0.0105,  0.2095,\n",
      "          -0.6425,  0.0748,  0.1998, -0.0160,  0.0223, -0.4261, -0.0643,\n",
      "          -0.2667, -0.3534,  0.2670, -0.0350,  0.2225,  0.2285, -0.3082,\n",
      "          -0.6304]]], grad_fn=<StackBackward>)\n",
      "Hidden state: tensor([[[-0.0478, -0.5431,  0.0997, -0.2324,  0.0138,  0.1760, -0.0274,\n",
      "          -0.0999, -0.0684, -0.1663,  0.2475,  0.0884, -0.3003, -0.2772,\n",
      "          -0.2035, -0.1211,  0.2084,  0.3077,  0.4153,  0.2399,  0.3368,\n",
      "           0.1871, -0.1179, -0.1679,  0.0261,  0.1721,  0.0880, -0.1811,\n",
      "           0.1808,  0.0879, -0.0167,  0.0511,  0.0214, -0.1042,  0.0921,\n",
      "          -0.0821, -0.5229, -0.0615, -0.3729, -0.2019,  0.2015,  0.0625,\n",
      "          -0.0060,  0.4505, -0.1952,  0.0985, -0.2364, -0.0105,  0.2095,\n",
      "          -0.6425,  0.0748,  0.1998, -0.0160,  0.0223, -0.4261, -0.0643,\n",
      "          -0.2667, -0.3534,  0.2670, -0.0350,  0.2225,  0.2285, -0.3082,\n",
      "          -0.6304]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chars in input data: {input_lang.n_chars}\")\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_chars, hidden_size=64).to(device)\n",
    "\n",
    "hidden = encoder.init_hidden()\n",
    "\n",
    "print(f\"Hidden state: {hidden}\")\n",
    "\n",
    "output, hidden = encoder(torch.tensor(21), hidden)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Hidden state shape: {hidden.shape}\")\n",
    "\n",
    "\n",
    "print(f\"Output: {output}\")\n",
    "print(f\"Hidden state: {hidden}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Example decoder in Encoder-Decoder architecture <b> WE DONT USE IT</b>, we will use Attention decoder instead. This one is only to introduce the concept of decoder.\n",
    "\n",
    "<img src=\"images/decoder-network.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chars in target data: 13\n",
      "Output shape: torch.Size([1, 13])\n",
      "Hidden state shape: torch.Size([1, 1, 64])\n",
      "Output: tensor([[-2.5416, -2.6538, -2.7066, -2.8975, -2.5685, -2.6640, -2.5171, -2.4762,\n",
      "         -2.6472, -2.6047, -2.4126, -2.2777, -2.5134]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "Hidden state: tensor([[[ 0.0463, -0.0412, -0.1089, -0.0750, -0.2551,  0.2022,  0.1875,\n",
      "          -0.1433, -0.0948,  0.1825, -0.0044,  0.0853, -0.0753,  0.0347,\n",
      "          -0.0101, -0.0502,  0.0603,  0.0605,  0.1429,  0.1422,  0.0260,\n",
      "           0.0137, -0.2558, -0.3137, -0.1612, -0.0095,  0.1899, -0.1191,\n",
      "          -0.0381,  0.2819,  0.0628,  0.1220,  0.2648, -0.0064, -0.1064,\n",
      "          -0.1815, -0.4039, -0.0181,  0.1713,  0.0944,  0.1834,  0.2286,\n",
      "           0.1672,  0.1851, -0.1682,  0.2012, -0.1542, -0.1794,  0.0296,\n",
      "          -0.6866, -0.0940,  0.1615,  0.1683,  0.0476, -0.0128,  0.1943,\n",
      "           0.0385, -0.1504, -0.0153,  0.0608,  0.0928,  0.0461, -0.1079,\n",
      "          -0.3438]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chars in target data: {output_lang.n_chars}\")\n",
    "\n",
    "\n",
    "decoder = DecoderRNN(64, output_lang.n_chars).to(device)\n",
    "\n",
    "# hidden = decoder.init_hidden()\n",
    "\n",
    "output, hidden = decoder(torch.tensor([[SOS_token]], device=device), hidden)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Hidden state shape: {hidden.shape}\")\n",
    "\n",
    "\n",
    "print(f\"Output: {output}\")\n",
    "print(f\"Hidden state: {hidden}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention decoder\n",
    "\n",
    "<img width=300px src=\"images/attention-decoder-network.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttentionDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30_000\n",
    "LEARNING_RATE = 0.005\n",
    "HIDDEN_SIZE = 64\n",
    "TEACHER_FORCING_RATIO = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[i], encoder_hidden)\n",
    "        encoder_outputs[i] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target  as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_lang.n_chars, HIDDEN_SIZE).to(device)\n",
    "decoder = AttentionDecoderRNN(HIDDEN_SIZE, output_lang.n_chars, dropout_p=0.1).to(device)\n",
    "\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=LEARNING_RATE)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pairs = [variables_from_pair(random.choice(pairs))\n",
    "                  for i in range(EPOCHS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr/anaconda3/envs/pumapython/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d7a7ad5df24528801ae1c97723b4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.5125999450683594\n",
      "Loss: 1.1206715323708274\n",
      "Loss: 0.8173559362238104\n",
      "Loss: 0.5885919224132191\n",
      "Loss: 0.5791624242609198\n",
      "Loss: 0.8763106086037376\n",
      "Loss: 0.6172269907864657\n",
      "Loss: 0.49876928329467773\n",
      "Loss: 0.22797547687183728\n",
      "Loss: 0.22864588824185458\n",
      "Loss: 0.3331551335074685\n",
      "Loss: 0.3626427867195823\n",
      "Loss: 0.18350672721862793\n",
      "Loss: 0.05678801103071733\n",
      "Loss: 0.3948114135048606\n",
      "Loss: 0.14968870986591687\n",
      "Loss: 0.059521160342476585\n",
      "Loss: 0.05851893533359875\n",
      "Loss: 0.1177993579344316\n",
      "Loss: 1.9571045962246982\n",
      "Loss: 0.014749405058947477\n",
      "Loss: 0.021961576559326866\n",
      "Loss: 0.007481871003454382\n",
      "Loss: 0.19452922994440253\n",
      "Loss: 0.06800693273544312\n",
      "Loss: 0.16283817724748093\n",
      "Loss: 0.7414084347811613\n",
      "Loss: 0.030698407780040394\n",
      "Loss: 0.00231440162116831\n",
      "Loss: 0.04002220251343467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm_notebook(range(EPOCHS)):\n",
    "    \n",
    "    pair = training_pairs[epoch]\n",
    "    input_tensor = pair[0]\n",
    "    target_tensor = pair[1]\n",
    "    \n",
    "\n",
    "    \n",
    "    loss = train(input_tensor, target_tensor, encoder,\n",
    "             decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Loss: {loss}\")\n",
    "    \n",
    "    losses.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss value\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show predictions generated by a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    droput_value = decoder.dropout_p\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        decoder.dropout_p = 0.0\n",
    "        \n",
    "        input_tensor = variable_from_sentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.init_hidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for i in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[i],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[i] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2char[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "        decoder.dropout_p = droput_value\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(input_word, output_word, attentions):\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(attentions.numpy())\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(len(input_word)))\n",
    "    ax.set_yticks(np.arange(len(output_word)))\n",
    "    # ... and label them with the respective list entries\n",
    "    ax.set_xticklabels(input_word)\n",
    "    ax.set_yticklabels(output_word)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "    output_word = \"\".join(output_word).replace(\"<EOS>\", \"\")\n",
    "\n",
    "    ax.set_title(f\"Input: {input_word}, Prediction: {output_word}\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    \n",
    "    rcParams['figure.figsize'] = 10, 20\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_word = \"3 02 97\"\n",
    "\n",
    "output_word, attentions = evaluate(\n",
    "    encoder, decoder, input_word)\n",
    "\n",
    "visualize_attention(input_word, output_word, attentions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
