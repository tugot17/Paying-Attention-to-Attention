\begin{thebibliography}


@article{markup-decompiler,
    author  = "Y. Deng et al.",
    title   = "What You Get Is What You See:A Visual Markup Decompiler",
    year    = "2016"
}


@article{unet,
    author  = "O. Oktay  et al.",
    title   = "Attention U-Net: Learning Where to Look for the Pancreas",
    year    = "2018"
}


@article{attention-is-all-you-need,
    author  = "A. Vaswani et al.",
    title   = "Attention Is All You Need",
    year    = "2017"
}


@article{first-paper,
    author  = "D. Bahdanau, K. Cho, Y. Bengio",
    title   = "Neural Machine Translation by Jointly Learning to Align and Translate",
    year    = "2014"
}


@article{seq-2-seq,
    author  = "I. Sutskever, O. Vinyals, Q. V. Le",
    title   = "Sequence to Sequence Learning with Neural Networks",
    year    = "2014"
}

@article{not-all-attention-is-neededr,
    author  = "L. Xue, X. Li, N. L. Zhang",
    title   = "Not All Attention Is Needed: Gated Attention Network",
    year    = "2019"
}

@article{image-caption,
    author  = "K. Xu et al.",
    title   = "Show, Attend and Tell: Neural Image CaptionGeneration with Visual Attention",
    year    = "2016"
}


@article{bert,
    author  = "J. Devlin et al.",
    title   = "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    year    = "2018"
}

@article{roberta,
    author  = "Y. Llu et al.",
    title   = "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
    year    = "2019"
}


@article{albert,
    author  = "Z. Lan et al.",
    title   = "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations",
    year    = "2019"
}


@article{gpt2,
    author  = "A. Radford et al.",
    title   = "Language Models are Unsupervised Multitask Learners",
    year    = "2019"
}

@article{res-attention,
    author  = "F. Wang et al.",
    title   = "Residual Attention Network for Image Classification",
    year    = "2019"
}


@article{treegen,
    author  = "Z. Sun et al.",
    title   = "TreeGen: A Tree-Based Transformer Architecture for Code Generation",
    year    = "2019"
}



\end{thebibliography}